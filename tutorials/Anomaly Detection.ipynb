{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Tutorial\n",
    "\n",
    "In this tutorial we will learn:\n",
    "\n",
    "- Getting Data: How to import data from PyCaret repository?\n",
    "- Setting up Environment: How to setup experiment in PyCaret to get started with building anomaly models?\n",
    "- Create Model: How to create a model and assign anomaly labels to original dataset for analysis?\n",
    "- Plot Model: How to analyze model performance using various plots?\n",
    "- Predict Model: How to assign anomaly labels to new and unseen dataset based on trained model?\n",
    "- Save / Load Model: How to save / load model for future use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger().setLevel(level=logging.ERROR)\n",
    "logging.getLogger('sintel').setLevel(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an instance of the DBExplorer\n",
    "\n",
    "Sintel requires the use of MongoDB to store data.\n",
    "In order to connect to the database, all you need to do is import and create an instance of the class.\n",
    "\n",
    "To create the `DBExplorer` instance you will need to pass:\n",
    "\n",
    "* `user`: An identifier of the user that is running Orion.\n",
    "* `database`: The name of the MongoDB database to use. This is optional and defaults to `sintel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sintel.db import DBExplorer\n",
    "\n",
    "db_name = 'sintel'\n",
    "dbex = DBExplorer(user='dyu', database=db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will directly create a connection to the database named `'sintel-ad'` at the default\n",
    "MongoDB host, `localhost`, and port, `27017`.\n",
    "\n",
    "In case you wanted to connect to a different database, host or port, or in case user authentication\n",
    "is enabled in your MongoDB instance, you can pass a dictionary or a path to a JSON file containing\n",
    "any required additional arguments:\n",
    "\n",
    "* `host`: Hostname or IP address of the MongoDB Instance. Defaults to `'localhost'`.\n",
    "* `port`: Port to which MongoDB is listening. Defaults to `27017`.\n",
    "* `username`: username to authenticate with.\n",
    "* `password`: password to authenticate with.\n",
    "* `authentication_source`: database to authenticate against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the `DBExplorer` instance, and to be sure that we are ready to follow\n",
    "the tutorial, let's do the following two set-up steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop the currently existing `sintel-ad` database\n",
    "\n",
    "**WARNING**: This will remove all the data that exists in this database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbex.drop_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make sure to have downloaded some demo data using the `orion.data.download_demo()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.data:Downloading Sintel Demo Data to folder data\n"
     ]
    }
   ],
   "source": [
    "from sintel.data import download_demo\n",
    "\n",
    "download_demo(path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a folder called `orion-data` in your current directory with the 3 CSV files\n",
    "that we will use later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add information to the database\n",
    "\n",
    "\n",
    "### 1. Add a Dataset\n",
    "\n",
    "In order to add a dataset you can use the `add_dataset` method, which has the following arguments:\n",
    "\n",
    "* `name (str)`: Name of the dataset\n",
    "* `entity (str)`: Name or Id of the entity which this dataset is associated to\n",
    "\n",
    "Let's create the `Demo Dataset` that we will use for our demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dbex.add_dataset(\n",
    "    name='NASA',\n",
    "    entity='NASA',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This call will try to create a new _Dataset_ object in the database and return it.\n",
    "\n",
    "We can now see the _Dataset_ that we just created using the `get_datasets` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ec1b4318e938ac1ae4</td>\n",
       "      <td>2023-01-25 19:20:12.127</td>\n",
       "      <td>NASA</td>\n",
       "      <td>NASA</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset_id             insert_time  name entity created_by\n",
       "0  63d180ec1b4318e938ac1ae4 2023-01-25 19:20:12.127  NASA   NASA        dyu"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add a Signal\n",
    "\n",
    "The next step is to add Signals. This can be done with the `add_signal` method, which expects:\n",
    "\n",
    "* `name (str)`: Name of the signal\n",
    "* `dataset (Dataset or ObjectID)`: Dataset Object or Dataset Id.\n",
    "* `start_time (int)`: (Optional) minimum timestamp to be used for this signal. If not given, it\n",
    "  defaults to the minimum timestamp found in the data.\n",
    "* `stop_time (int)`: (Optional) maximum timestamp to be used for this signal. If not given, it\n",
    "  defaults to the maximum timestamp found in the data.\n",
    "* `data_location (str)`: URI of the dataset\n",
    "* `timestamp_column (int)`: (Optional) index of the timestamp column. Defaults to 0.\n",
    "* `value_column (int)`: (Optional) index of the value column. Defaults to 1.\n",
    "\n",
    "For example, adding the `S-1` signal to the Demo Dataset that we just created could be done like\n",
    "this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbex.add_signal(\n",
    "#     name='S-1',\n",
    "#     dataset=dataset,\n",
    "#     data_location=os.path.join('data', 'S-1.csv')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also add all the signals that exist inside a folder by using the `add_signals`\n",
    "method, passing a `signals_path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbex.add_signals(\n",
    "    dataset=dataset,\n",
    "    signals_path='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this is done, we can see that one signal has been created for each one of the CSV\n",
    "files that we downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>data_location</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ec1b4318e938ac1ae5</td>\n",
       "      <td>2023-01-25 19:20:12.334</td>\n",
       "      <td>E-1</td>\n",
       "      <td>63d180ec1b4318e938ac1ae4</td>\n",
       "      <td>1222819200</td>\n",
       "      <td>1468951200</td>\n",
       "      <td>data/E-1.csv</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63d180ec1b4318e938ac1ae6</td>\n",
       "      <td>2023-01-25 19:20:12.357</td>\n",
       "      <td>P-1</td>\n",
       "      <td>63d180ec1b4318e938ac1ae4</td>\n",
       "      <td>1222819200</td>\n",
       "      <td>1468540800</td>\n",
       "      <td>data/P-1.csv</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63d180ec1b4318e938ac1ae7</td>\n",
       "      <td>2023-01-25 19:20:12.371</td>\n",
       "      <td>S-1</td>\n",
       "      <td>63d180ec1b4318e938ac1ae4</td>\n",
       "      <td>1222819200</td>\n",
       "      <td>1442016000</td>\n",
       "      <td>data/S-1.csv</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  signal_id             insert_time name  \\\n",
       "0  63d180ec1b4318e938ac1ae5 2023-01-25 19:20:12.334  E-1   \n",
       "1  63d180ec1b4318e938ac1ae6 2023-01-25 19:20:12.357  P-1   \n",
       "2  63d180ec1b4318e938ac1ae7 2023-01-25 19:20:12.371  S-1   \n",
       "\n",
       "                    dataset  start_time   stop_time data_location created_by  \n",
       "0  63d180ec1b4318e938ac1ae4  1222819200  1468951200  data/E-1.csv        dyu  \n",
       "1  63d180ec1b4318e938ac1ae4  1222819200  1468540800  data/P-1.csv        dyu  \n",
       "2  63d180ec1b4318e938ac1ae4  1222819200  1442016000  data/S-1.csv        dyu  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_signals(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a Template\n",
    "\n",
    "The next thing we need to add is a _Template_ to the Database using the `add_template` method.\n",
    "\n",
    "This method expects:\n",
    "\n",
    "* `name (str)`: Name of the template.\n",
    "* `template (dict or str)`: Optional. Specification of the template to use, which can be one of:\n",
    "    * An MLPipeline instance\n",
    "    * The name of a registered template\n",
    "    * a dict containing the MLPipeline details\n",
    "    * The path to a pipeline JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 14:20:12.984154: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64/\n",
      "2023-01-25 14:20:12.984178: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "template = dbex.add_template(\n",
    "    name='lstmdt',\n",
    "    template='./pipelines/orion_lstmdt.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the _Template_ that we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ed1b4318e938ac1ae8</td>\n",
       "      <td>2023-01-25 19:20:13.828</td>\n",
       "      <td>lstmdt</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                template_id             insert_time    name created_by\n",
       "0  63d180ed1b4318e938ac1ae8 2023-01-25 19:20:13.828  lstmdt        dyu"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_templates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, during this step, apart from a _Template_ object, a _Pipeline_ object has also been\n",
    "registred with the same name as the _Template_ and using the default hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ed1b4318e938ac1ae9</td>\n",
       "      <td>2023-01-25 19:20:13.833</td>\n",
       "      <td>lstmdt</td>\n",
       "      <td>63d180ed1b4318e938ac1ae8</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pipeline_id             insert_time    name  \\\n",
       "0  63d180ed1b4318e938ac1ae9 2023-01-25 19:20:13.833  lstmdt   \n",
       "\n",
       "                   template created_by  \n",
       "0  63d180ed1b4318e938ac1ae8        dyu  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we want to use a configuration different from the default, we might want to\n",
    "create another _Pipeline_ with custom hyperparameter values.\n",
    "\n",
    "In order to do this we will need to call the `add_pipeline` method passing:\n",
    "\n",
    "* `name (str)`: Name given to this pipeline\n",
    "* `template (Template or ObjectID)`: Template or the corresponding id.\n",
    "* `hyperparameters (dict or str)`: dict containing the hyperparameter details or path to the\n",
    "  corresponding JSON file. Optional.\n",
    "\n",
    "For example, if we want to specify a different number of epochs for the LSTM primitive of the\n",
    "pipeline that we just created we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hyperparameters = {\n",
    "   'keras.Sequential.LSTMTimeSeriesRegressor#1': {\n",
    "       'epochs': 1,\n",
    "       'verbose': True\n",
    "   }\n",
    "}\n",
    "pipeline = dbex.add_pipeline(\n",
    "   name='lstmdt_1_epoch',\n",
    "   template=template,\n",
    "   hyperparameters=new_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see how a new _Pipeline_ was created in the Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ed1b4318e938ac1ae9</td>\n",
       "      <td>2023-01-25 19:20:13.833</td>\n",
       "      <td>lstmdt</td>\n",
       "      <td>63d180ed1b4318e938ac1ae8</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63d180ee1b4318e938ac1aea</td>\n",
       "      <td>2023-01-25 19:20:14.078</td>\n",
       "      <td>lstmdt_1_epoch</td>\n",
       "      <td>63d180ed1b4318e938ac1ae8</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pipeline_id             insert_time            name  \\\n",
       "0  63d180ed1b4318e938ac1ae9 2023-01-25 19:20:13.833          lstmdt   \n",
       "1  63d180ee1b4318e938ac1aea 2023-01-25 19:20:14.078  lstmdt_1_epoch   \n",
       "\n",
       "                   template created_by  \n",
       "0  63d180ed1b4318e938ac1ae8        dyu  \n",
       "1  63d180ed1b4318e938ac1ae8        dyu  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an Experiment\n",
    "\n",
    "Once we have a _Dataset_ with _Signals_ and a _Template_, we are ready to add an\n",
    "_Experiment_.\n",
    "\n",
    "In order to run an _Experiment_ we will need to:\n",
    "\n",
    "1. Get the _Dataset_ and the list of _Signals_ that we want to run the _Experiment_ on.\n",
    "2. Get the _Template_ which we want to use for the _Experiment_\n",
    "3. Call the `add_experiment` method passing all these with an experiment, a project name and a\n",
    "   username.\n",
    "\n",
    "For example, if we want to create an experiment using the _Dataset_, the _Signals_ and the\n",
    "_Template_ that we just created, we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = dbex.add_experiment(\n",
    "    name='Demo Experiment',\n",
    "    project='Demo Project',\n",
    "    template=template,\n",
    "    dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create an _Experiment_ object in the database using the indicated _Template_\n",
    "and all the _Signals_ from the given _Dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>insert_time</th>\n",
       "      <th>name</th>\n",
       "      <th>project</th>\n",
       "      <th>template</th>\n",
       "      <th>dataset</th>\n",
       "      <th>signals</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d180ee1b4318e938ac1aeb</td>\n",
       "      <td>2023-01-25 19:20:14.111</td>\n",
       "      <td>Demo Experiment</td>\n",
       "      <td>Demo Project</td>\n",
       "      <td>63d180ed1b4318e938ac1ae8</td>\n",
       "      <td>63d180ec1b4318e938ac1ae4</td>\n",
       "      <td>[63d180ec1b4318e938ac1ae5, 63d180ec1b4318e938a...</td>\n",
       "      <td>dyu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              experiment_id             insert_time             name  \\\n",
       "0  63d180ee1b4318e938ac1aeb 2023-01-25 19:20:14.111  Demo Experiment   \n",
       "\n",
       "        project                  template                   dataset  \\\n",
       "0  Demo Project  63d180ed1b4318e938ac1ae8  63d180ec1b4318e938ac1ae4   \n",
       "\n",
       "                                             signals created_by  \n",
       "0  [63d180ec1b4318e938ac1ae5, 63d180ec1b4318e938a...        dyu  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbex.get_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a Datarun\n",
    "\n",
    "Once we have created our _Experiment_ object we are ready to start executing _Pipelines_ on our\n",
    "_Signals_.\n",
    "\n",
    "For this we will need to use the `orion.runner.start_datarun` function, which expects:\n",
    "\n",
    "* `orex (OrionExplorer)`: The `OrionDBExplorer` instance.\n",
    "* `experiment (Experiment or ObjectID)`: Experiment object or the corresponding ID.\n",
    "* `pipeline (Pipeline or ObjectID)`: Pipeline object or the corresponding ID.\n",
    "\n",
    "This will create a _Datarun_ object for this _Experiment_ and _Pipeline_ in the database,\n",
    "and then it will start creating and executing _Signalruns_, one for each _Signal_ in the _Experiment_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trigger a _Datarun_ using the `lstmdt_1_epoch` _Pipeline_ that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.runners.anomaly_detection:Datarun 63d180ee1b4318e938ac1aec started\n",
      "INFO:sintel.runners.anomaly_detection:Signalrun 63d180ee1b4318e938ac1aed started\n",
      "INFO:sintel.runners.anomaly_detection:Signal E-1; Signalrun 63d180ee1b4318e938ac1aed\n",
      "INFO:sintel.runners.anomaly_detection:Signalrun 63d180ee1b4318e938ac1afc started\n",
      "INFO:sintel.runners.anomaly_detection:Signal P-1; Signalrun 63d180ee1b4318e938ac1afc\n",
      "INFO:sintel.runners.anomaly_detection:Signalrun 63d180ee1b4318e938ac1b0b started\n",
      "INFO:sintel.runners.anomaly_detection:Signal S-1; Signalrun 63d180ee1b4318e938ac1b0b\n"
     ]
    }
   ],
   "source": [
    "from sintel.runners.anomaly_detection import start_datarun\n",
    "\n",
    "start_datarun(dbex, experiment, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add anomaly detection specific information to the database \n",
    "\n",
    "The following collections will be added:\n",
    "- **signal_raw**: For each signal, save raw csv data with a given interval \n",
    "- **prediction**: For each signalrun, save the prediction results\n",
    "- **period**: For each signalrun, save the X after preprocessing in a periodical manner (year->month->day->hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:1/3: Processing signal E-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update raw*  interval: 21600s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:2/3: Processing signal P-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update raw*  interval: 21600s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:3/3: Processing signal S-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update raw*  interval: 21600s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:1/3: Processing signalrun 63d180ee1b4318e938ac1aed\n",
      "INFO:sintel.db.utils:Pipeline name lstmdt_1_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update period* my_interval: 360m, day_bin_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:2/3: Processing signalrun 63d180ee1b4318e938ac1afc\n",
      "INFO:sintel.db.utils:Pipeline name lstmdt_1_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update period* my_interval: 360m, day_bin_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sintel.db.utils:3/3: Processing signalrun 63d180ee1b4318e938ac1b0b\n",
      "INFO:sintel.db.utils:Pipeline name lstmdt_1_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*update period* my_interval: 360m, day_bin_num: 4\n"
     ]
    }
   ],
   "source": [
    "from sintel.db.utils import update_db\n",
    "\n",
    "update_db(dbex._fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RESTful APIs to explore results\n",
    "\n",
    "Please follow the steps below to start your exploration:\n",
    "1. Open `./sintel/config.yml` and ensure `db` is of the value with `db_name` used in this tutorial \n",
    "2. Launch sintel backend with command:\n",
    "```bash\n",
    "sintel run -v\n",
    "```\n",
    "3. Open a new tab in your browser and access http://localhost:3000/apidocs/\n",
    "4. Start your exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MTV â€” the visual interface to explore results\n",
    "\n",
    "1.  Download MTV\n",
    "```bash\n",
    "git clone https://github.com/sintel-dev/MTV mtv\n",
    "```\n",
    "2. Follow the instruction (https://github.com/sintel-dev/MTV) to launch MTV client end\n",
    "3. Go http://localhost:4200 and start your exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sintel-mtvtest",
   "language": "python",
   "name": "sintel-mtvtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
